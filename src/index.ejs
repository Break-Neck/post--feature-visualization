<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://distill.pub/template.v2.js"></script>
  <style>
    <%= require("./style.css") %>
  </style>
</head>

<body>

<d-front-matter>
  <script type="text/json">{
  "title": "Feature Visualization",
  "description": "How neural networks build up their understanding of images",
  "authors": [
    {
      "author":"Chris Olah",
      "authorURL":"https://colah.github.io/",
      "affiliation":"Google Brain Team",
      "affiliationURL":"https://g.co/brain"
    },
    {
      "author":"Alexander Mordvintsev",
      "authorURL":"https://znah.net/",
      "affiliation":"Google Research",
      "affiliationURL":"https://research.google.com/"
    },
    {
      "author":"Ludwig Schubert",
      "authorURL":"https://schubert.io/",
      "affiliation":"Google Brain Team",
      "affiliationURL":"https://g.co/brain"
    }
  ]
  }</script>
</d-front-matter>


<d-title style="contain: style; overflow: visible;">
  <h1>Визуализация признаков</h1>
  <p style="grid-column: text;">Как нейронные сети выстраивают свое понимание изображений</p>
  <figure class="base-grid">
    <div style="grid-column: screen; padding-left: 16px; padding-right: 16px;" id="googlenet-examples"></div>
    <figcaption style="grid-column: text;">
      Представление признаков позволяет увидель, как GoogLeNet<d-cite key="szegedy2015going"></d-cite>, обученная на датасете ImageNet<d-cite key="deng2009imagenet"></d-cite> строит свое понимание изображений с каждым новым слоем.
      Визуализации всех каналов доступна в <a href="appendix/">приложении</a>.
    </figcaption>
  </figure>
</d-title>

<d-article>
  
<p>
  Все острее встает проблема интерпретации нейронных сетей людьми, решение этой проблемы
  привело к развитию такого направления, как интерпретация нейронных сетей.
  С его развитием, начали сливаться два направления исследования: визуализация признаков (<translate-original>feature visualisation</translate-original>) и атрибутивность (<translate-original>attribution</translate-original>).
</p>


<figure id="fv-vs-attribution" class="grid" style="">
  <div>
    <div class="images">
      <img src="images/objectives/neuron.png">
      <img src="images/objectives/channel.png">
    </div>
    <figcaption>
      <strong>Визуализация признаков</strong> отвечает на вопросы о том, на что нейронная сеть (или ее части) "смотрит", генерируя примеры.
    </figcaption>
  </div>
  <div>
    <div class="images">
      <img src="images/attribution-1.png"/>
      <img src="images/attribution-2.jpg" style/>
    </div>
    <figcaption>
    <strong>Атрибутивность</strong>
      <d-footnote>
        Как это часто бывает с молодой областью, интерпретация нейронных сетей не имеет устоявшейся терминологии.
        Атрибутивность имела много других названий -- включая "визуализация признаков"! -- но последние работы склонны использовать такие термины как "атрибутивность" и "области внимания" (<translate-original>"saliency maps"</translate-original>).
      </d-footnote>
    изучает, какая часть примера отвечает за определенные отклики в сети.
    </figcaption>
  </div>
</figure>

<p>
  В данной статье рассказывается о визуализации признаков.
  Несмотря на то, что это мощная техника, ее использование требует учета некоторых деталей.
  В этой статье мы рассмотрим главные проблемы и изучим основные способы их решения, получив достаточно простыми методами качественную визуализацию. Будут показаны способы исследования изменений в том, на что реагируют нейроны, как они взаимодействуют, и как улучшить процесс оптимизации.
</p>

<!-- 
<p>
  Neural network feature visualization is a powerful technique. It can answer questions about what a network -- or parts of a network -- are looking for by generating idealized examples of what the network is trying to find.
  Along with attribution it forms one of the two main threads of research in neural network interpretability.
</p> -->
<!-- 
<p>
  Over the last few years, the field has made great strides in feature visualization. Actually getting it to work, however, involves a number of details. In this article, we examine the major issues and explore common approaches to solving them.
</p>
<p>
  We find that remarkably simple methods can produce high-quality visualizations. Along the way we introduce a few tricks for exploring variation in what neurons react to, how they interact, and how to improve the optimization process.
</p> -->

<hr />
<!-- =================================================== -->
<h2 id="optimization">Визуализация признаков через Оптимизацию</h2>

<p>
  Нейронные сети, вообще говоря, дифиренцируемы по их входным параметрам.
  Если мы хотим выявить, что нужно подать на вход, чтобы вызвать определенный отклик (неважно,
  для внутреннего нейрона, или для конечного выхода сети), мы можем использовать производные, чтобы интерактивно менять вход, пока не достигнем цели <d-cite key="erhan2009visualizing"></d-cite>.
</p>

<figure class="base-grid" style="min-height: 168px;">
  <figcaption style="grid-column: kicker;">Начиная со случайного шума, мы оптимизируем изображение, чтобы активировать нужный нейрон (слой mixed4a, объект 11).</figcaption>
  <d-figure id="opt-progress" style="grid-column: text;"></d-figure>
</figure>

<p>
  Несмотря на идейную простоту, в данном подходе есть некоторые тонкие моменты, которые необходимо учесть для корректной работы.
  Мы рассмотрим их, вместе с распространенными подходами к решению, в части "<a href="#enemy-of-feature-vis">Враг визуализации признаков</a>".
</p>

<h3 id="optimization-objectives">Цели оптимизации</h3>

<p>
  Примеров чего нам хочется?
  Это главный вопрос в работе с примерами, независимо от того, просматриваем ли мы датасет в поисках примеров, или оптимизируем изображения, чтобы создать их с нуля.
  Есть большое множество вариантов для поиска:
</p>

<figure class="base-grid" id="optimization-objectives">
  <style>
    #optimization-objectives .objectives {
      grid-column: text;
      grid-template-columns: repeat(1, 1fr);
    }
    
    #optimization-objectives .objective {
      display: grid;
      grid-template-columns: repeat(2, 1fr) 1.1fr;
    }
    
    #optimization-objectives .objectives figcaption {
      padding: 4px 8px;
      word-wrap: break-word;
      word-break: break-word;
    }
    
    #optimization-objectives .objective .objective-icon {
      padding: 8px;    
    }
    
    @media (min-width: 512px) {
      #optimization-objectives .objectives {
        grid-template-columns: repeat(5, 1fr);
        grid-column-gap: 16px;
      }
      
      #optimization-objectives .objective {
        display: flex;
        flex-flow: column;
      }
      
      #optimization-objectives .objectives figcaption {
        padding: 0;
        padding-top: 4px;
        word-wrap: break-word;
        word-break: break-word;
      }
    }
  </style>
  
  <figcaption style="grid-column: kicker;">
    <p>Различные <strong>цели оптимизации(<translate-original>optimization objectives</translate-original>)</strong> показывают, на что нацелены разные части сети.</p>
    <br>
    <p><code><strong>n</strong></code> номер слоя <br />
      <code><strong>x,y</strong></code> позиция в пространстве<br />
      <code><strong>z</strong></code> номер канала <br />
      <code><strong>k</strong></code> класс</p>
  </figcaption>
  
  <div class="objectives grid">
    <div class="objective">
      <div class="objective-icon">
        <img inline src="static/images/objectives/objectives_neuron.svg">
      </div>
      <img class="objective-opt" src="images/objectives/neuron.png">
      <figcaption><strong>Neuron</strong><br/><code>layer<sub>n</sub>[x,y,z]</code></figcaption>
    </div>
    
    <div class="objective">
      <div class="objective-icon">
        <img inline src="static/images/objectives/objectives_channel.svg">
      </div>
      <img class="objective-opt" src="images/objectives/channel.png">
      <figcaption><strong>Channel</strong><br/><code>layer<sub>n</sub>[:,:,z]</code></figcaption>
    </div>
    
    <div class="objective">
      <div class="objective-icon">
        <img inline src="static/images/objectives/objectives_layer.svg">
      </div>
      <img class="objective-opt" src="images/objectives/layer.png">
      <figcaption><strong>Layer</strong>/DeepDream<br/><code>layer<sub>n</sub>[:,:,:]<sup>2</sup></code></figcaption>
    </div>
    
    <div class="objective">
      <div class="objective-icon">
        <img inline src="static/images/objectives/objectives_logits_pre.svg">
      </div>
      <img class="objective-opt" src="images/objectives/logits.png">
      <figcaption><strong>Class Logits</strong><br/><code>pre_softmax[k]</code></figcaption>
    </div>
    
    <div class="objective">
      <div class="objective-icon">
        <img inline src="static/images/objectives/objectives_logits_post.svg">
      </div>
      <img class="objective-opt" src="images/objectives/logits_post.png">
      <figcaption><strong>Class Probability</strong><br/><code>softmax[k]</code></figcaption>
    </div>
  </div>
</figure>

<p>
  Если мы хотим понять отдельные признаки, мы можем поискать примеры, где они имеют высокие значения, для <em>нейрона</em> ли, или всего <em>канала</em>.
  Мы использовали канальную цель оптимизации для создания большинства изображений в этой статье.
</p>
    
<p>
  Если мы хотим понять <em>слой</em> целиком, мы можем использовать цель "DeepDream" <d-cite key="mordvintsev2015inceptionism"></d-cite>, ища изображения, которые сеть признает "интересными".
</p>
<!-- <p>
  And if we want to create examples of output classes from a classifier, we have two options -- optimizing <em>class logits</em> before the softmax or optimizing <em>class probabilities</em> after the softmax.
  One can see the logits as the evidence for each class, and the probabilities as the likelihood of each class given the evidence.
  Unfortunately, the easiest way to increase the probability softmax gives to a class is often to make the alternatives unlikely rather than to make the class of interest likely <d-cite key="simonyan2013deep"></d-cite>.
  This can be fixed by very strong regularization with generative models, in which case the probabilities can be a very principled thing to optimize.
  From our experience, optimizing pre-softmax logits produces images of better visual quality.<d-footnote>
    While the standard explanation is that maximizing probability doesn't work very well because you can just push down evidence for other classes, an alternate hypothesis is that it's just harder to optimize through the softmax function. We understand this has sometimes been an issue in adversarial examples, and the solution is to optimize the LogSumExp of the logits instead. This is equivalent to optimizing softmax but generally more tractable. Our experience was that the LogSumExp trick doesn't seem better than dealing with the raw probabilities.
  </d-footnote>
</p> -->

<p>
  Если в случае классификации мы хотим создать примеры для каждого выходного класса, у нас есть 2 выбора: оптимизировать вход или выход <em>softmax</em> слоя. Вход можно рассматривать,
  как признаки каждого класса, а вероятности как правдоподобие каждого класса при условии заданных значений признаков.
  К сожалению, простейший способ увеличить вероятность, приписываемую классу через <em>softmax</em> это зачатую сделать другие классы "почти невозможными", вместо того, чтобы увеличить собственно, целевое правдоподобие <d-cite key="simonyan2013deep"></d-cite>.
  По нашему опыту, оптимизация входа <em>softmax</em> слоя дает более привлекательные визуально изображения.
  <d-footnote>
    Несмотря на то, что стандартное объяснение говорит, что максимизация правддоподобия
    не работает, та как можно просто уменьшить правдоподобие других классов, есть альтернативное объяснение, что такая оптимизация на самом деле сложнее. Мы понимаем,
    что такое действительно случалось в некоторых конкурсах, и что существует решение, состоящее в оптимизации логарифма суммы экспонент входа <em>softmax</em> слоя. Это заменяет задачу на эквивалентную, но в общем случае более простую. На нашем опыте, такой переход не давал преимуществ в сравнении с работой с чистыми вероятностями.
    <br />
    <br />
    Независимо от причин, это можно исправить, используя очень сильную регуляризацию. В таком случае, вероятности могут быть сложнооптимизируемыми.
  </d-footnote>
</p>

<p>
  Упомянутые целевые функции это только вершина айсберга -- их существует боьше, чем кто-то может испробовать за раз.
  Стоят упоминания также целевые функции, используемые в переносе стилей <d-cite key="gatys2015neural"></d-cite>, которые показывают различные виды стилей и содержимого, выучиваемого нейроннойсетью; используемые в инверсии модели на основе оптимизации <d-cite key="mahendran2015understanding"></d-cite>, которая помогает увидеть запоминаемую и отбрасываемую моделью информацию.
  Мы находимся только в начале пути к пониманию, какие целевые функции заслуживают внимания, в этой области большой простор для исследований.
</p>

<h3 id="why-optimization">Зачем визуализировать используя оптимизацию?</h3>

<p>
  Оптимизация может дать нам пример ввода, который вызывает желаемое поведение
  - Но зачем это надо?
  Не могли бы мы просто просмотреть набор данных для примеров, которые вызывают желаемое поведение?
</p>

<p>
  Оказывается, такой подход позволяет понять, что действительно ищет модель,
  потому что он отделяет вещи, вызывающие интересующие нас отклики, от вещей, которые просто коррелируют с причинами.
  Например, рассмотрим следующие нейроны, визуализированные с примерами данных и оптимизацией:
</p>

<figure style="grid-column: screen;">
  <d-figure class="base-grid" id="example-optimization-comparison"></d-figure>
</figure>

<p>
  Оптимизация также является гибким подходом.
  Например, если мы хотим изучить, как нейроны совместно представляют информацию,
  мы можем легко узнать, как надо изменить отдельный, чтобы получить отклик дополнительного нейрона.
  Эта гибкость также может быть полезной при визуализации того, как функции меняются по мере прохождения сети.
  Если бы мы ограничились пониманием работы модели на фиксированных примерах, темы, подобные этим, были бы намного сложнее исследовать.
</p>

<p>
  С другой стороны, есть также серьезные проблемы с визуализацией признаков оптимизацией. В следующих разделах мы рассмотрим методы для получения разнообразных визуализаций, понимания взаимодействия нейронов и предотвращения высокочастотных артефактов.
</p>


<!-- =================================================== -->
<hr/>
<h2 id="diversity">Разнообразие</h2>

<!-- TODO: improve las sentence -->
<p>
  Показывают ли наши примеры полную картину?
  Когда мы создаем примеры с помощью оптимизации, нужно быть очень осторожными. Вполне возможно, что настоящие примеры по-прежнему вводят нас в заблуждение, только показывая нам одну «грань» того, что представляет собой признак.
</p>

<p>
  Рассмотрение датасетов целиком имеет большое преимущество.
  Просматривая наши данные, можно найти разнообразные примеры.
  Это не просто позволяет нам интенсивно активировать нейрон: мы можем посмотреть на весь спектр, чтобы узнать, что активирует нейрон в разной степени.
</p>

<!-- <figure class="l-page-outset"><img src="images/vis_ActivationSpectrum.svg" style="min-height: 150px;"></img></figure> -->


<figure style="grid-column: screen;" class="shaded-figure">
  <d-figure class="base-grid" id="optimization-and-examples"></d-figure>
</figure>


<!-- <figure class="l-page-outset row" id="tmptest">
  <img class="column" src="https://cnsviewer2.corp.google.com/cns/in-d/home/ludwigschubert/visualize_channels/diagrams/mixed4a-00492/0-min.jpg">
  <img class="column" src="https://cnsviewer2.corp.google.com/cns/in-d/home/ludwigschubert/visualize_channels/diagrams/mixed4a-00492/1-some_negative.jpg">
  <img class="column" src="https://cnsviewer2.corp.google.com/cns/in-d/home/ludwigschubert/visualize_channels/diagrams/mixed4a-00492/2-zero.jpg">
  <img class="column" src="https://cnsviewer2.corp.google.com/cns/in-d/home/ludwigschubert/visualize_channels/diagrams/mixed4a-00492/3-some_positive.jpg">
  <img class="column" src="https://cnsviewer2.corp.google.com/cns/in-d/home/ludwigschubert/visualize_channels/diagrams/mixed4a-00492/4-max.jpg">
</figure> -->
<p>
  Напротив, оптимизация, как правило, дает нам только один "экстремальный"
  позитивный пример - и, если постараться, экстремальный негативный.
  Есть ли способ, получить такое же разнообразие оптимизацией?
</p>

<h3 id="diversity-with-optimization">Достижение разнообразия используя оптимизационный подход</h3>

<p>
  Отдельная часть сети может реагировать на широкий диапазон входных данных. Например, на уровне класса классификатор, который был обучен распознавать собак, должен распознавать как крупным планом лица, так и более широкие изображения профиля, даже если они выглядят совершенно по-разному.
  Ранняя работа <d-cite key="mneuron2015">Вей <i>и др.</i></d-cite> пытается продемонстрировать внутриклассовое разнообразие, записывая отклики по всем датасету, кластеризуя их и оптимизируя для центроидов кластера, раскрывая различные найденные свойства класса.
</p>

<p>
  Другой подход Нгуен, Йосински и соавторов заключался в поиске набора данных для различных примеров и использовании их в качестве отправных точек для процесса оптимизации <d-cite key="nguyen2016multifaceted"></d-cite>.
  Идея состоит в том, что это инициирует оптимизацию в разных аспектах, так что полученный в результате пример продемонстрирует эту грань. В более поздней работе они сочетают визуализацию классов с генеративной моделью, которую можно отбирать для различных примеров <d-cite key="nguyen2016plug"></d-cite>.
  Их первый подход имел ограниченный успех, и в то время как генеративный подход к модели работает очень хорошо - мы обсудим его более подробно в разделе о регуляризации в <a href="#learned-priors">изученных предпосылках</a> - это может быть немного сложно.
</p>

<p>
  Cуществует очень простой способ добиться разнообразия: добавление члена, отвечающего за это
  <d-footnote>
      В данной статье мы используем подход, основанный на идеях переноса стиля.
      Согласно данной работе, мы начинаем с вычисления матрицы Грамма <d-math>G</d-math> каналов, где:
      <d-math block>
        G_{i,j} = \text{layer}_n\text{[:, :, i]} \cdot \text{layer}_n\text{[:, :, j]}
      </d-math>
      После этого, мы вычисляем член, отвечающий за разнообразие: инвертированную косинусную меру близости пар представлений.
      <d-math block>
        C_{\text{diversity}} = - \sum_{a} \sum_{b\neq a} ~ \frac{\text{vec}(G_a) \cdot \text{vec}(G_b)}{||\text{vec}(G_a)||~||\text{vec}(G_b)||} 
      </d-math>
    После этого мы максимизируем данный член вместе с другими стандартными целевыми функциями.
  </d-footnote>  в формулу, учитывая в нем, насколько отличаются разные примеры.
  Это слагаемое может принимать много различных видов, и мы не можем однозначно указать все их премущества.
  Один из вариантов -- штрафовать косинусную меру близости различных примеров.
  Другой -- использовать идеи из переноса стилей, принуждая отображение признаков в различных стилях.
</p>

<p>
  В нейронах нижнего уровня разнообразие может выявить различные грани, которые представляет собой функция:
</p>

<figure class="grid l-page" style="grid-template-columns: repeat(6, 1fr)">
  <div style="">
    <img style="max-width: 147px;" src="images/diversity/mixed4a_97_optimized.png" />
    <figcaption>Простая оптимизация</figcaption>
  </div>
  <div style="grid-column-end: span 4">
    <img src="images/diversity/mixed4a_97_diversity.png" />
    <figcaption>
      Оптимизация с разнообразием, выявляющим четыре различных грани. <i>Слой mixed4a, объект 97</i>
    </figcaption>
  </div>
  <div style="">
    <img style="max-width: 147px;"src="images/diversity/mixed4a_97_examples.jpg" />
    <figcaption>Приметы датасета</figcaption>
  </div>
</figure>


<p>
  Различные визуализации признаков позволяют нам более точно определить, что активирует нейрон, позволяя, смотря на примеры из датасета, проверять гипотезы о том, какие входы будут активировать нейрон.
</p>
<p>
  Например, рассмотрим этот результат простой оптимизации.
</p>

<p>  
  <span style="display: block; float: left; width: 147px; margin-right: 1em; margin-bottom: 0.5em; margin-top: 3px">
    <img src="images/diversity/mixed4a_143_optimized.png" />
    <span class="figcaption">Простая оптимизация</span>
  </span>
  Глядя только на него, можно предположить, что этот нейрон активируется на вершине головы собаки, так как оптимизация показывает как глаза, так и нижние края.
  Однако, глядя на оптимизацию с учетом разнообразия, мы видим результаты оптимизации, которые не включают в себя глаза, а также один, который включает в себя изогнутые вверх края. Таким образом, мы должны расширить наше ожидание того, что этот нейрон активирует, главным образом, в отношении текстуры меха. Проверка этой гипотезы показывает, что это в целом правильно. Обратите внимание на ложку с текстурой и цветом, достаточно похожим на шерсть собаки, чтобы активировать нейрон.
</p>

<figure class="base-grid">
  <div style="grid-column: text;">
    <img src="images/diversity/mixed4a_143_diversity.png" />
    <figcaption>
      Оптимизация с разнообразием <i>Слой mixed4a, объект 143</i>
    </figcaption>
  </div>
  <div style="grid-column: gutter;">
    <img style="max-width: 147px;"src="images/diversity/mixed4a_143_examples.jpg" />
    <figcaption>Примеры датасета</figcaption>
  </div>
</figure>

<p>
  Эффект разнообразия может быть еще более впечатляющим в нейронах более высокого уровня, где он может показать нам различные типы объектов, стимулирующих нейрон.
  Например, один нейрон реагирует на разные виды шаров, хотя они и сильно отличаются по виду.
</p>

<figure class="grid l-page" style="grid-template-columns: repeat(6, 1fr)">
  <div style="">
    <img style="max-width: 147px;" src="images/diversity/mixed5a_9_optimized.png" />
    <figcaption>Простая оптимизация</figcaption>
  </div>
  <div style="grid-column-end: span 4">
    <img src="images/diversity/mixed5a_9_diversity.png" />
    <figcaption>Оптимизация с разнообразием показывает различные типы шаров. <i>Слой mixed5a, объект 9</i></figcaption>
  </div>
  <div style="">
    <img style="max-width: 147px;"src="images/diversity/mixed5a_9_examples.jpg" />
    <figcaption>Примеры датасета</figcaption>
  </div>
</figure>

<p>
  Этот более простой подход имеет ряд недостатков:
  Во-первых, давление, влияющие на различие примеров, может привести к появлению не связанных между собой артефактов (таких как глаза).
  Кроме того, оптимизация может привести к тому, что примеры будут отличаться неестественным образом.
  Например, в приведенном выше примере можно было бы увидеть примеры футбольных мячей, отделенных от других видов мячей, таких как гольф или теннисные мячи.
  Подходы, учитывающие весь датасет, как <d-cite key="mneuron2015">Вей <i>и др.</i></d-cite> могут разделять признаки более естественным путем -- однако, они могут быть не настолько полезными для понимания поведения модели на различных входных данных.
</p>

<p>
  Разнообразие также начинает вызывать более фундаментальную проблему: в то время как приведенные выше примеры представляют собой в основном согласованную идею, существуют также нейроны, представляющие странные смеси идей.
  Ниже, нейрон реагирует на два типа животных лиц, а также на кузовы.
</p>

<figure class="grid l-page" style="grid-template-columns: repeat(6, 1fr)">
  <div style="">
    <img style="max-width: 147px;" src="images/diversity/mixed4e_55_optimized.png" />
    <figcaption>Простая оптимизация</figcaption>
  </div>
  <div style="grid-column-end: span 4">
    <img src="images/diversity/mixed4e_55_diversity.png" />
    <figcaption>Оптимизация с учетом разнообразия показывает кошек, лис, а еще... машины. <i>Слой mixed4e, объект 55</i></figcaption>
  </div>
  <div style="">
    <img style="max-width: 147px;"src="images/diversity/mixed4e_55_examples.jpg" />
    <figcaption>Примеры датасета</figcaption>
  </div>
</figure>

<p>
  Примеры, подобные этим, предполагают, что нейроны не обязательно являются правильными семантическими единицами для понимания нейронных сетей.
</p>

<!-- =================================================== -->
<hr/>
<h2 id="interaction">Взаимодействия между нейронами</h2>

<p>
  Если нейроны не подходят для понимания нейронных сетей, то что подходит?
  В реальной жизни комбинации нейронов работают вместе, чтобы представлять изображения в нейронных сетях.
  Индивидуальные нейроны являются базовыми направлениями пространства активации, и неясно, что они должны быть более особенными, чем любое другое направление.
</p>

<p>
  <d-cite key="szegedy2013intriguing">Szegedy <i>и др.</i></d-cite> обнаружили, что случайные направления кажутся столь же значимыми, как и основные направления.
  Совсем недавно <d-cite key="netdissect2017">Бау, Чжоу <i>и др.</i></d-cite> обнаружили, что базисные направления интерпретируются чаще, чем случайные.
  Наш опыт в целом согласуется с обоими результатами: мы обнаруживаем, что случайные направления часто кажутся интерпретируемыми, но более низкими, чем базисные.
</p>

<figure class="base-grid" >
  <figcaption style="grid-column: kicker;">
    Примеры набора данных и оптимизированные примеры <strong>случайных направлений</strong>
    в пространстве активации. Указанные здесь направления были отобраны для интерпретируемости.
  </figcaption>
  <d-figure style="grid-column: text-start / page-end;" id="random-optimization-and-examples"></d-figure>
</figure>

<p>
  Мы также можем определить интересные направления в пространстве активации, выполнив арифметику на нейронах.
  Например, если мы добавим «черно-белый» нейрон к «мозаичному» нейрону, мы получим черно-белую версию мозаики.
  Это напоминает семантическую арифметику словесных вложений, как видно из скрытых пространств Word2Vec или генеративных моделей.
</p>

<figure class="base-grid shaded-figure">
  <figcaption style="grid-column: kicker;">
    Совместно оптимизируя два нейрона можно получить представление об их взаимодействии.
  </figcaption>
  <d-figure style="grid-column: text-start / screen-end; overflow: visible; contain: unset;" id="linear-combinations"></d-figure>
</figure>

<p>
  Эти примеры показывают нам, как нейроны совместно представляют изображения.
  Для лучшего понимания, мы также можем использовать интерполяцию.
  <d-footnote>Цель оптимизации - линейная интерполяция между целями отдельных каналов. Чтобы получить более приятную на глаз интерполяцию, мы также добавляем небольшое слагаемое выравнивания, которое поощряет активацию более низких уровней. Кроме того, мы используем комбинацию отдельных и разделяемых параметров изображения, чтобы упростить алгоритм оптимизации, чтобы объекты выстраивались в линию, при этом предоставляя им свободу для создания любого изображения, в котором он нуждается.</d-footnote>
  Это похоже на интерполяцию в скрытом пространстве генерирующих моделей.
</p>

<figure class="base-grid shaded-figure">
  <d-figure style="grid-column: text-start / page-end;" id="interpolation"></d-figure>
</figure>

<p>
  Это простейшие примеры взаимодействия нейронов.
  Истина заключается в том, что мы почти не знаем, как выбрать значимые направления или существуют даже особо значимые направления.
  Независимо от нахождения направлений, есть также вопросы о том, как они взаимодействуют -- например, интерполяция может показать нам, как взаимодействует небольшое число направлений, но на самом деле существует сотни взаимодействующих направлений.
</p>


<!-- =================================================== -->
<hr/>
<h2 id="enemy-of-feature-vis">Враг визуализации признаков</h2>

<p>
  Если вы хотите визуализировать признаки, вы можете просто оптимизировать изображение, чтобы "зажигать" нейроны.
  К сожалению, это не работает.
  Вместо этого вы оказываетесь в виде оптической иллюзии нейронной сети -- изображение, полное шума и бессмысленных высокочастотных паттернов, на которые сильно реагирует сеть.
</p>

<figure class="shaded-figure base-grid">
  <figcaption style="grid-column: kicker;">
    <p>Даже при хорошем подборе темпа обучения, вы получите шумы.</p><br />
    <p>Результаты оптимизации увеличены для демонстрации деталей и артефактов.</p>
  </figcaption>
  <d-figure style="grid-column: text;" id="optimize-naive"></d-figure>
</figure>

<p>
  Эти образцы, по-видимому, являются "обманками", они находят способы активировать нейроны, так, как это не происходит в реальной жизни.
  Если вы будете оптимизировать достаточно долго, вы, как правило, увидите что-то из того, что нейрон действительно обнаруживает, но изображение полностью "затеняется" этими высокочастотными шаблонами.
  Эти шаблоны кажутся сильно связанными с феноменом негативных примеров <d-cite key="szegedy2013intriguing"></d-cite>.
</p>

<p>
  Мы не совсем понимаем, почему формируются эти высокочастотные шаблоны,
  но важной частью, по-видимому, являются чередующиеся свертки и пулинги, которые создают высокочастотные структуры в градиенте <d-cite key="odena2016deconvolution"></d-cite>.
</p>

<figcaption>Каждая <b>свертка и пулиг</b> создает "эффект шахматной доски" в градиенте, когда мы распространяем через него ошибку. <dt-cite key="odena2016deconvolution"></dt-cite></figcaption>
<figure style="grid-column: page;">
  <d-figure id="frequency-artifacts"></d-figure>
</figure>


<p>
  Эти высокочастотные шаблоны показывают нам, что, хотя дарованная оптимизационным подходом свобода от ограничений привлекательна, это обоюдоострый меч.
  Без каких-либо ограничений на изображения мы заканчиваем спорными примерами.
  Это, конечно, интересно, но если мы хотим понять, как эти модели работают в реальной жизни, нам нужно как-то обойти это...
</p>

<h3 id="regularization">Спектры регуляризации</h3>

<p>
  Работа с этими высокочастотными шумами была одной из основных задач визуализации объектов.
  Если вы хотите получить полезную визуализацию, вам нужно наложить более естественную структуру, используя какой-то регуляризатор или ограничение.
</p>

<p>
  Фактически, если вы посмотрите на наиболее заметные документы по визуализации функций, одним из их основных пунктов будет, как правило, подход к регуляризации.
  Исследователи пробовали много разных вещей!
</p>

<p>
  Мы можем думать обо всех этих подходах как о жизни в спектре, исходя из того, насколько сильно они регуляризируют модель.
  С одной стороны, если мы вообще не будем использовать регуляризацию, мы сталкиваемся с негативными примерами.
  С другой, при использовании только примеров из датасета мы сталкиваемся со всеми ограничениями, которые мы обсуждали ранее.
  А в середине у нас есть три основных семейства вариантов регуляризации.
</p>

<%= require('raw-loader!./diagrams/RegReviewRendered.txt') %>
<!-- <d-figure id="feature-vis-history"></d-figure> -->

<h3 id="regularization-families"> Три типа регуляризации</h3>

<p>
  Рассмотрим эти три промежуточные категории регуляризации более подробно.
</p>

<p>
  <b>Частотный штраф</b> directly targets the high frequency noise these methods suffer from.
  непосредственно направлен на высокочастотный шум, от которого страдают эти методы.
   Он может явно наказывать дисперсию между соседними пикселями (суммарную вариацию) <d-cite key="mahendran2015understanding"></d-cite>, или неявно наказывать высокочастотный шум за счет размытия изображения на каждом этапе оптимизации <d-cite key="nguyen2015deep"></d-cite>.<d-footnote>
    Если рассуждать о размытии в пространстве Фурье, то это эквивалентно добавлению масштабированного штрафа L2 к цели, что штрафует каждый компонент Фурье на основе его частоты.
  </d-footnote>
  К сожалению, эти подходы также препятствуют законным высокочастотным функциям, таким как края и шум.
  Это можно немного улучшить, используя двусторонний фильтр, который сохраняет края, а не размытие <d-cite key="tyka2016bilateral"></d-cite>.
</p>

<p>
  (В некоторых работах используются аналогичные методы для снижения высоких частот в градиенте, прежде чем они накапливаются при визуализации <d-cite key="oygard2015vis,mordvintsev2016deepdreaming"></d-cite>.
  Эти методы в некотором смысле очень похожи на вышеизложенное и в некотором роде радикально отличаются - мы рассмотрим их в следующем разделе, <a href="#preconditioning">Предобуславливание и Параметризация</a>.)
</p>

<figure class="shaded-figure base-grid">
  <figcaption style="grid-column: kicker;">
    <p>Частотная регуляризация напрямую направлена на высокочастотный шум</p>
  </figcaption>
  <d-figure style="grid-column: text;" id="regularizer-playground-freq"></d-figure>
</figure>
<!--
  - none
  - Total variance
  - Blur
-->


<p>
  <b>Устойчивость к изменениям</b> пытается найти примеры, которые все еще активируют целевую задачу оптимизации, даже если мы слегка их преобразуем.
  Даже небольшое количество кажется очень эффективным в случае изображений <d-cite key="mordvintsev2015inceptionism"></d-cite>, 
  особенно в сочетании с более общим регуляризатором для высоких частот <d-cite key="oygard2015vis,mordvintsev2016deepdreaming"></d-cite>.
  Конкретно это означает, что мы стохастически поворачиваем или масштабируем изображение перед применением этапа оптимизации.
</p>


<!--<figure id="optimize-jitter" class="l-page-outset"></figure>-->

<figure class="shaded-figure base-grid">
  <figcaption style="grid-column: kicker;">
    <p>Стохастическое преобразование изображения перед применением этапа оптимизации подавляет шум</p>
  </figcaption>
  <d-figure style="grid-column: text;" id="regularizer-playground-robust"></d-figure>
</figure>

<!--TODO(colah): Make a diagram of unconstraint opt vs paramaterized opt vs prior? Discuss using an inverse model?-->

<!-- technically most challenging -->

<p>
  <b id="learned-priors">Изученных предпосылки.</b>
  Наши предыдущие регуляризаторы используют очень простые эвристики, чтобы держать примеры разумными.
  Естественным следующим шагом является выучить модели реальных данных и попытаться обеспечить ее соблюдение.
  С сильной моделью это похоже на поиск по набору данных.
  Этот подход дает большинство фотореалистичных визуализаций, но может быть неясно, что из результатов пришло из модели, а что из предпосылок.
</p>

<p>
  Один из подходов состоит в том, чтобы изучить генератор, который отображает точки в скрытом пространстве на примеры ваших данных, таких как GAN или VAE, и оптимизировать в этом скрытом пространстве <d-cite key="nguyen2016synthesizing"></d-cite>.
  Альтернативный подход состоит в том, чтобы изучить пердпосылки, что позволяет работать с градиентом вероятности; это позволяет одновременно оптимизировать предпосылки
  вместе с вашей функцией <d-cite key="nguyen2016plug,mordvintsev2015inceptionism"></d-cite>.
  Когда кто-то оптимизирует предпосылки и вероятность класса, восстанавливается генеративная модель данных, обусловленная этим конкретным классом.
  Наконец, <d-cite key="mneuron2015">Вей <i>и др.</i></d-cite> приблизили генеративную модель, по крайней мере, для распределения цветов, штрафуя за расстояние между патчами вывода и ближайшими патчами, полученными из базы данных патчей изображений, собранных из датасета.
</p>




<!-- =================================================== -->
<hr/>
<h2 id="preconditioning">Предобуславливание и параметризация</h2>

<br>

<p>
  В предыдущей секции, мы рассмотрели несколько методов <d-cite key="oygard2015vis,mordvintsev2016deepdreaming"></d-cite> уменьшающих долю высоких частот <i>в градиенте</i>, а не в самой визуализации.
  Непонятно, действительно ли это регуляризатор: он сопротивляется высоким частотам,
  но все же позволяет им формироваться, когда градиент последовательно заставляет его.
  Если это не регуляризатор, что же это за преобразование градиента?
</p>

<p>
  Преобразование такого градиента на самом деле является довольно мощным инструментом - он называется «предобуславливание» в оптимизации.
  Вы можете думать об этом как о методе наискорейшего спуска, чтобы оптимизировать одну и ту же цель,
  но в другой параметризации пространства или при другом понимании расстояния.
  <d-footnote>
    Размытие градиента<d-cite key="oygard2015vis"></d-cite> эквивалентно градиентному спуску при другой параметризации пространства изображений, где высокочастотные размеры растянуты, чтобы движение в этих направлениях было медленнее. Нормализация лапласианской пирамиды градиента <d-cite key="mordvintsev2016deepdreaming"></d-cite> является своего рода адаптивным способом обучения в одном и том же пространстве.
  </d-footnote>
  Это изменит направление спуска будет самым крутым, и как быстро оптимизация движется в каждом направлении, но это не изменяет минимальные значения.
  Если есть много локальных минимумов, их области могут могут растягиваться, изменяя, в какой из них сойдется процесс оптимизации.
   В результате использование правильного предусловителя может значительно упростить задачу оптимизации.
</p>
<p>
  Как мы можем выбрать предобуславливатель, который даст нам эти преимущества?
  Хорошая догадка -- это то, что делает ваши данные декоррелированными и "выбеленными".
  В случае изображений это означает выполнение градиентного спуска в базисе Фурье,
  <d-footnote>
    Это указывает на глубокий факт преобразования Фурье.
    Пока корреляция согласована между пространственными позициями, такими как корреляция между пикселем и его левым соседом, одинакова во всех позициях изображения, коэффициенты Фурье будут независимыми переменными.
    Для этого заметим, что такая пространственно-согласованная корреляция может быть выражена как свертка, а по теореме свертки становится точечным умножением после преобразования Фурье.
  </d-footnote>
  с частотами, масштабированными так, чтобы они имели равную энергию.
  <d-footnote>
      Обратите внимание, что мы должны быть осторожны, чтобы цвета были также декорированы. Преобразования Фурье декорируют пространственно, но корреляция будет по-прежнему существовать между цветами.
      Чтобы решить эту проблему, мы явно измеряем корреляцию между цветами в датасете и используем разложение Холески для их декорреляции. Сравните направления наискорейшего спуска до и после декоративных цветов:
      
      <br />
      <span style="display: block; padding-top: 1em;">
        <span style="display: inline-block;">
          <img style="height: 112px; width: 112px; display: block;" src="images/correlated_colors.jpeg"/>
          <span class="figcaption">
            Скоррелированные цвета
          </span>
        </span>
        <span style="display: inline-block;">
          <img style="height: 112px; width: 112px; display: block;" src="images/decorrelated_colors.jpeg"/>    
          <span class="figcaption">
            Нескоррелированные цвета
          </span>  
        </span>
      </span>
  </d-footnote>
</p>
<p>
  Давайте посмотрим, как использование разных мер расстояния изменяет направление наискорейшего спуска.
  Обычный L<sup>2</sup> градиент может сильно отличаться от направления градиента наискорейшего спуска в L<sup>∞</sup> метрике декоррелированного пространства:
</p>

<figure class="shaded-figure base-grid">
  <figcaption style="grid-column: kicker">
    Три направления наискорейшего спуска под разными понятиями расстояния
  </figcaption>
  <d-figure style="grid-column: text-start / screen-end;" id="steepest-descent"></d-figure>
</figure>

<p>
  Все эти направления являются возможными направлениями спуска для одной и той же функции,
  но мы видим, что они радикально отличаются друг от друга.
  Обратите внимание, что оптимизация в декоррелированном пространстве уменьшает высокие частоты, в то время как L <sup>∞</sup> увеличивает их.
</p>

<p>
  Использование декоррелированного направления спуска приводит к совершенно иной визуализации.
  Трудно делать действительно честные сравнения из-за гиперпараметров, но
  полученные визуализации кажутся намного лучше - и развиваются быстрее.
</p>

<figure class="shaded-figure base-grid">
  <figcaption style="grid-column: kicker;">
    <p>Сочетание устойчивости к предобуславливанию и трансформации улучшает качество еще больше</p>
  </figcaption>
  <d-figure style="grid-column: text;" id="opt-explore2"></d-figure>
</figure>

<p>
  (Если не указано иное, изображения в этой статье были оптимизированы в декоррелированном пространстве и набором устойчивых к преобразованиям методов.
  <d-footnote>
    Изображения были оптимизированы для 2560 шагов в цвето-декоррелированном фурье пространстве, используя Адам-оптимизатор со скоростью обучения 0,05.
    Мы использовали каждое из следующих преобразований в данном порядке на каждом шаге оптимизации:<br /><br />
    • Создание отступа от границ на 16 пикселей, чтобы избежать краевых артефактов <br />
    • Дрожание до 16 пикселей <br />
    • Масштабирование со значением, случайным образом выбранным из этого списка: 1, 0,975, 1,025, 0,95, 1,05 <br />
    • Вращение на случайный угол, выбранном из этого списка; в градусах: -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5 <br />
    • Дрожание во второй раз до 8 пикселей <br />
    • Обрезка отступов <br />
  </d-footnote>)
</p>

<p>
  Является ли предобуславливание просто ускорением спуска, приводящим нас к тому же минимуму, что и обычный градиентный спуск?
  Или это также регуляризатор, изменяющий, приоритеты локальных минимумов?
  Трудно сказать точно.
  С одной стороны, градиентный спуск, похоже, продолжает улучшаться, поскольку, если вы экспоненциально увеличиваете количество шагов оптимизации - он не сходится, он просто движется очень медленно.
  С другой стороны, если вы отключите все другие регуляризаторы, предобуславливание, похоже, уменьшит частотные характеристики.
</p>

<!-- =================================================== -->
<hr/>
<h2 id="conclusion">Заключение</h2>
  
<p class="">
  Визуализация нейронных признаков достигла больших успехов за последние несколько лет.
  Как сообщество, мы разработали принципиальные способы создания наглядных визуализаций.
  Мы наметили ряд важных проблем и нашли способы их решения.
</p>

<p class="">
  В стремлении сделать нейронные сети интерпретируемыми, визуализация признаков
  выделяется как одно из наиболее перспективных и развитых направлений исследований.
  Сама по себе визуализация признаков никогда не даст полностью удовлетворительного
  понимания. Мы рассматриваем его как один из фундаментальных строительных блоков, который
  в сочетании с дополнительными инструментами, позволит людям понять эти системы.
</p>

<p>
  Остается еще много важной работы по улучшению визуализации функций.
  Среди них выделяются: понимание взаимодействия нейронов, определение того, какие единицы являются наиболее значимыми для понимания активации нейронной сети, и достижение целостного взгляда на грани признаков.
</p>

<p>
  Тем временем, любопытным читателям предлагается изучить <a href="appendix/"> визуализацию всех каналов GoogLeNet </a>.
</p>

</d-article>

<d-appendix>
  <h3 id="acknowledgements">Благодарности</h3>
  <p>
    Мы чрезвычайно благодарны Шан Картеру и Яну Гудфеллоу.
    Шань вдумчиво отзывался, особенно о дизайне статьи.
    Ян благородно вызвался сделать ревью этой статьи - мы бы не смогли опубликовать ее без него.
  </p>
  
  <p>
    Мы также благодарны за комментарии, мысли и поддержку
    Арвинд Сатьянараян, Ян Джонсон,
    Грег Коррадо, Блейз Агуера и Аркас,
    Кэтрин Е., Майкл Нильсен, Эмма Пирсон, Дарио Амодей,
    Майк Тыка,
    Андреа Ведалди, Рут Фонг, Джейсон Фрейденфельдс,
    Джеффри Хинтон,
    Тимон Рубан,
    Были Ким, Мартин Ваттенберг и Фернанда Вигас.
  </p>
  
  <p>
    This work was made possible by many open source tools, for which we are grateful. 
    In particular, all of our experiments were based on Tensorflow<d-cite key="abadi2016tensorflow"></d-cite>.
  </p>

  <h3 id="author-contributions">Author Contributions</h3>
  <p>
    <strong>Writing, Exposition, and Diagram Contributions.</strong> Chris drafted most of the text of the article and made the original version of most interactive diagrams. Ludwig made the neuron addition, dataset examples, and interpolation diagrams, as well as refined the others. Ludwig also created the appendix that visualizes all of GoogLeNet.
  </p>
  <p>
    <strong>Research Contributions.</strong> The biggest technical contribution of this work is likely the section on preconditioning. Alex discovered in prior work that normalizing gradient frequencies had a radical effect on visualizing neurons. Chris reframed this as adaptive gradient descent in a different basis. Together, they iterated on a number of ways of parameterizing images. Similarly, Alex originally introduced the use of diversity term, and Chris reﬁned using it. Chris did the exploration of interpolating between neurons. 
  </p>
  <p>
    <strong>Infrastructure Contributions.</strong> All experiments are based on code written by Alex, some of which was <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb">published previously</a>. Alex, Chris and Ludwig all contributed significantly to refining this into the present code base. Alex and Chris introduced particularly important abstractions.
  </p>
  
  <h3 id="discussion-review">Discussion and Review</h3>
  <p>
    <a href="https://github.com/distillpub/post--feature-visualization/issues/1">Review 1 - Anonymous</a><br>
    <a href="https://github.com/distillpub/post--feature-visualization/issues/4">Review 2 - Anonymous</a><br>
    <a href="https://github.com/distillpub/post--feature-visualization/issues/6">Review 3 - Anonymous</a><br>
  </p>

  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<d-bibliography src="bibliography.bib"></d-bibliography>

</body>
